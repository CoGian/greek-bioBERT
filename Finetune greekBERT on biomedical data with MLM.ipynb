{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Finetune greekBERT on biomedical data with MLM.ipynb","provenance":[],"authorship_tag":"ABX9TyPnSKUE37qXZCBZh4tF94Ru"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ksP3Tea7HGCy","executionInfo":{"status":"ok","timestamp":1609087897106,"user_tz":-120,"elapsed":9845,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"e13b7389-100a-46d4-a113-48c8b84899ff"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 34.1MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 45.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=a74a35d35ce94a6a5b4385664d95b6d67d7f9ee4e4196ea52cb1aba8e940d288\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHzTPPew_-6T","executionInfo":{"status":"ok","timestamp":1609087905542,"user_tz":-120,"elapsed":5526,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"c97cffbb-4ba2-4b4a-f949-5b19bd44e565"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","print(tf.__version__)\n","from tensorflow.keras.optimizers import Adam\n","import transformers\n","from transformers import TFAutoModelWithLMHead, AutoTokenizer\n","import logging\n","import json\n","# no extensive logging \n","logging.getLogger().setLevel(logging.NOTSET)\n","\n","AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":3,"outputs":[{"output_type":"stream","text":["2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rpRQCvGoG7Zl","executionInfo":{"status":"ok","timestamp":1609087930418,"user_tz":-120,"elapsed":551,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}}},"source":["with open(\"sentences_dataset.json\", \"r\" , encoding=\"utf-8\") as fin:\n","  sentences = json.load(fin)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLFIad_j_XFy","executionInfo":{"status":"ok","timestamp":1609088024888,"user_tz":-120,"elapsed":562,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}}},"source":["MAX_LEN = 128\n","BATCH_SIZE = 16 # per TPU core\n","TOTAL_STEPS = len(sentences) // 16 * 4  # thats approx 4 epochs\n","EVALUATE_EVERY = 200\n","LR =  1e-5\n","\n","PRETRAINED_MODEL = 'nlpaueb/bert-base-greek-uncased-v1'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7JDD8ZX_3BG","executionInfo":{"status":"ok","timestamp":1609088653971,"user_tz":-120,"elapsed":8443,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"a6f3e584-23dd-4736-ea24-ba68e6797b66"},"source":["def connect_to_TPU():\n","    \"\"\"Detect hardware, return appropriate distribution strategy\"\"\"\n","    try:\n","        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","        # set: this is always the case on Kaggle.\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print('Running on TPU ', tpu.master())\n","    except ValueError:\n","        tpu = None\n","\n","    if tpu:\n","        tf.config.experimental_connect_to_cluster(tpu)\n","        tf.tpu.experimental.initialize_tpu_system(tpu)\n","        strategy = tf.distribute.TPUStrategy(tpu)\n","    else:\n","        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","        strategy = tf.distribute.get_strategy()\n","\n","    global_batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n","\n","    return tpu, strategy, global_batch_size\n","\n","\n","tpu, strategy, global_batch_size = connect_to_TPU()\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Running on TPU  grpc://10.90.164.106:8470\n","WARNING:tensorflow:TPU system grpc://10.90.164.106:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.90.164.106:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.90.164.106:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.90.164.106:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["REPLICAS:  8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIthKWF__55p","executionInfo":{"status":"ok","timestamp":1609088154130,"user_tz":-120,"elapsed":3952,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"a6896d7c-e54e-439b-9aae-0a584fdfea9f"},"source":["%%time\n","\n","def regular_encode(texts, tokenizer, maxlen=512):\n","    enc_di = tokenizer.batch_encode_plus(\n","        texts, \n","        return_attention_mask=False, \n","        return_token_type_ids=False,\n","        pad_to_max_length=True,\n","        max_length=maxlen,\n","        truncation=True\n","    )\n","    \n","    return np.array(enc_di['input_ids'])\n","    \n","\n","tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n","X_train = regular_encode(sentences, tokenizer, maxlen=MAX_LEN)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json HTTP/1.1\" 200 0\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/vocab.txt HTTP/1.1\" 200 0\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 4.33 s, sys: 155 ms, total: 4.48 s\n","Wall time: 3.33 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EI5QCYZJAVUK","executionInfo":{"status":"ok","timestamp":1609088226929,"user_tz":-120,"elapsed":556,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}}},"source":["def prepare_mlm_input_and_labels(X):\n","    # 15% BERT masking\n","    inp_mask = np.random.rand(*X.shape)<0.15 \n","    # do not mask special tokens\n","    inp_mask[X<=102] = False\n","    # set targets to -1 by default, it means ignore\n","    labels =  -1 * np.ones(X.shape, dtype=int)\n","    # set labels for masked tokens\n","    labels[inp_mask] = X[inp_mask]\n","    \n","    # prepare input\n","    X_mlm = np.copy(X)\n","    # set input to [MASK] which is the last token for the 90% of tokens\n","    # this means leaving 10% unchanged\n","    inp_mask_2mask = inp_mask  & (np.random.rand(*X.shape)<0.90)\n","    X_mlm[inp_mask_2mask] = 103  # mask token is the last in the dict\n","\n","    # set 10% to a random token\n","    inp_mask_2random = inp_mask_2mask  & (np.random.rand(*X.shape) < 1/9)\n","    X_mlm[inp_mask_2random] = np.random.randint(3, 250001, inp_mask_2random.sum())\n","    \n","    return X_mlm, labels\n","\n","\n","\n","# masks and labels\n","X_train_mlm, y_train_mlm = prepare_mlm_input_and_labels(X_train)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCd4kyPNAiqj","executionInfo":{"status":"ok","timestamp":1609088356766,"user_tz":-120,"elapsed":836,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}}},"source":["def create_dist_dataset(X, y=None, training=False):\n","    dataset = tf.data.Dataset.from_tensor_slices(X)\n","\n","    ### Add y if present ###\n","    if y is not None:\n","        dataset_y = tf.data.Dataset.from_tensor_slices(y)\n","        dataset = tf.data.Dataset.zip((dataset, dataset_y))\n","        \n","    ### Repeat if training ###\n","    if training:\n","        dataset = dataset.shuffle(len(X)).repeat()\n","\n","    dataset = dataset.batch(global_batch_size).prefetch(AUTO)\n","\n","    ### make it distributed  ###\n","    dist_dataset = strategy.experimental_distribute_dataset(dataset)\n","\n","    return dist_dataset\n","    \n","    \n","train_dist_dataset = create_dist_dataset(X_train_mlm, y_train_mlm, True)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7ySdynnGQMB","executionInfo":{"status":"ok","timestamp":1609088714877,"user_tz":-120,"elapsed":49281,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"3394b66f-dfc7-40e3-bdfc-b479a94a4861"},"source":["%%time\n","\n","def create_mlm_model_and_optimizer():\n","    with strategy.scope():\n","        model = TFAutoModelWithLMHead.from_pretrained(PRETRAINED_MODEL)\n","        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n","    return model, optimizer\n","\n","\n","mlm_model, optimizer = create_mlm_model_and_optimizer()\n","mlm_model.summary()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_tf_auto.py:776: FutureWarning: The class `TFAutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `TFAutoModelForCausalLM` for causal language models, `TFAutoModelForMaskedLM` for masked language models and `TFAutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json HTTP/1.1\" 200 0\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n","DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /nlpaueb/bert-base-greek-uncased-v1/resolve/main/tf_model.h5 HTTP/1.1\" 302 0\n","All model checkpoint layers were used when initializing TFBertForMaskedLM.\n","\n","All the layers of TFBertForMaskedLM were initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"tf_bert_for_masked_lm_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  112330752 \n","_________________________________________________________________\n","mlm___cls (TFBertMLMHead)    multiple                  27903416  \n","=================================================================\n","Total params: 112,957,880\n","Trainable params: 112,957,880\n","Non-trainable params: 0\n","_________________________________________________________________\n","CPU times: user 8.18 s, sys: 7.17 s, total: 15.3 s\n","Wall time: 48.8 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CDR_bzJmGSbL","executionInfo":{"status":"ok","timestamp":1609088916234,"user_tz":-120,"elapsed":817,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}}},"source":["def define_mlm_loss_and_metrics():\n","    with strategy.scope():\n","        mlm_loss_object = masked_sparse_categorical_crossentropy\n","\n","        def compute_mlm_loss(labels, predictions):\n","            per_example_loss = mlm_loss_object(labels, predictions)\n","            loss = tf.nn.compute_average_loss(\n","                per_example_loss, global_batch_size = global_batch_size)\n","            return loss\n","\n","        train_mlm_loss_metric = tf.keras.metrics.Mean()\n","        \n","    return compute_mlm_loss, train_mlm_loss_metric\n","\n","\n","def masked_sparse_categorical_crossentropy(y_true, y_pred):\n","    y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n","    y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n","    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_masked,\n","                                                          y_pred_masked,\n","                                                          from_logits=True)\n","    return loss\n","\n","            \n","            \n","def train_mlm(train_dist_dataset, total_steps=2000, evaluate_every=200):\n","    step = 0\n","    ### Training lopp ###\n","    for tensor in train_dist_dataset:\n","        distributed_mlm_train_step(tensor) \n","        step+=1\n","\n","        if (step % evaluate_every == 0):   \n","            ### Print train metrics ###  \n","            train_metric = train_mlm_loss_metric.result().numpy()\n","            print(\"Step %d, train loss: %.2f\" % (step, train_metric))     \n","\n","            ### Reset  metrics ###\n","            train_mlm_loss_metric.reset_states()\n","            \n","        if step  == total_steps:\n","            break\n","\n","\n","@tf.function\n","def distributed_mlm_train_step(data):\n","    strategy.run(mlm_train_step, args=(data,))\n","\n","\n","@tf.function\n","def mlm_train_step(inputs):\n","    features, labels = inputs\n","\n","    with tf.GradientTape() as tape:\n","        predictions = mlm_model(features, training=True)[0]\n","        loss = compute_mlm_loss(labels, predictions)\n","\n","    gradients = tape.gradient(loss, mlm_model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, mlm_model.trainable_variables))\n","\n","    train_mlm_loss_metric.update_state(loss)\n","    \n","\n","compute_mlm_loss, train_mlm_loss_metric = define_mlm_loss_and_metrics()"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQLd4j6aGY76","executionInfo":{"status":"ok","timestamp":1609089778033,"user_tz":-120,"elapsed":862327,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"14d99860-2df7-416f-91e5-c231b4a23279"},"source":["train_mlm(train_dist_dataset, TOTAL_STEPS, EVALUATE_EVERY)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f583f355660>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f5856b9ee58> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f583f355660>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f5856b9ee58> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f583f355660>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f5856b9ee58> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f58545308c8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f58545308c8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: AutoGraph could not transform <function wrap at 0x7f58545308c8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Step 200, train loss: 1.13\n","Step 400, train loss: 0.93\n","Step 600, train loss: 0.79\n","Step 800, train loss: 0.67\n","Step 1000, train loss: 0.56\n","Step 1200, train loss: 0.47\n","Step 1400, train loss: 0.40\n","Step 1600, train loss: 0.33\n","Step 1800, train loss: 0.27\n","Step 2000, train loss: 0.23\n","Step 2200, train loss: 0.19\n","Step 2400, train loss: 0.16\n","Step 2600, train loss: 0.13\n","Step 2800, train loss: 0.11\n","Step 3000, train loss: 0.10\n","Step 3200, train loss: 0.08\n","Step 3400, train loss: 0.07\n","Step 3600, train loss: 0.06\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7kgDwc_5JRXz","executionInfo":{"status":"ok","timestamp":1609089864180,"user_tz":-120,"elapsed":3717,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}}},"source":["mlm_model.save_pretrained('greekBERT')"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzFAd276O3EO","executionInfo":{"status":"ok","timestamp":1609091428987,"user_tz":-120,"elapsed":704,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"97c2aed1-f90c-4ca7-fab5-5db2bd1ae971"},"source":["text_1 = 'Το τσιγάρο κάνει [MASK] στην υγεία αλλά μου αρέσει να [MASK]'\n","# text_1 = 'η ραβδομυόλυση ορίζεται ως [MASK], το οποίο εμφανίζεται μετά από καταστροφή (λύση) ή διαταραχή στην παραγωγή/κατανάλωση ενέργειας των μυϊκών κυττάρων'\n","# EN: 'The poet wrote a [MASK].'\n","input_ids = tokenizer.encode(text_1)\n","print(tokenizer.convert_ids_to_tokens(input_ids))\n","len(input_ids)"],"execution_count":112,"outputs":[{"output_type":"stream","text":["['[CLS]', 'το', 'τσιγαρο', 'κανει', '[MASK]', 'στην', 'υγεια', 'αλλα', 'μου', 'αρεσει', 'να', '[MASK]', '[SEP]']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["13"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLPD6QS_O5RS","executionInfo":{"status":"ok","timestamp":1609091430958,"user_tz":-120,"elapsed":1922,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}},"outputId":"57566705-beab-40d1-a600-53c5b871efe7"},"source":["input_ids = tokenizer.encode(text_1, return_tensors=\"tf\")\n","outputs = mlm_model(input_ids)\n","output_ids = []\n","for i in range(1,12):\n","  output_ids.append(tf.math.argmax(outputs.logits[0][i]).numpy())\n","\n","print(tokenizer.convert_ids_to_tokens(output_ids))\n","print(output_ids)"],"execution_count":113,"outputs":[{"output_type":"stream","text":["['το', 'τσιγαρο', 'κανει', 'κακο', 'στην', 'υγεια', 'αλλα', 'μου', 'αρεσει', 'να', 'ζω']\n","[345, 9148, 451, 1190, 360, 1045, 374, 386, 1697, 348, 2704]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6L76Fi3kO-Ui","executionInfo":{"status":"ok","timestamp":1609090630349,"user_tz":-120,"elapsed":632,"user":{"displayName":"KONSTANTINOS GIANTSIOS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxlSaGw_pDJddrfa5wDkeM2wZVe_78dWhctaGe=s64","userId":"07245582309685361544"}}},"source":[""],"execution_count":67,"outputs":[]}]}